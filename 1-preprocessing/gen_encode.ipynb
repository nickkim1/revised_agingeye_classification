{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General\n",
    "##### General Pipeline\n",
    "1) Wget the right gtf and fasta ref genome files for the Drosophila (or whatever organism) genome into appropriate directories\n",
    "\n",
    "2) Then parse GTF file for start/end coordinates for each gene. ATAC-seq data: split this interval into non-overlapping windows of x bp and assign peak counts. RNA-seq data: find TSS of each gene and do +/- specified x bases for each one. Then output BED file(s) delimited by start, stop coords you just made + the label. \n",
    "\n",
    "3) Next, run getfasta on the BED file(s) you just made. This will output a bunch of fasta files with just the gene_ids + actual sequences for each window interval you defined. \n",
    "\n",
    "4) Finally, run a script to concatenate together the outputted fasta files from getfasta and your bed files. The outputted CSV file will have the sequences themselves (rather than just start/stop coords) for each window and their corresponding label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess RNA-seq data \n",
    "\n",
    "Run scripts to preprocess RNA-seq data (in fasta file format) into BED files with sequences of +/- x bp windows up and downstream of the TSS respectively (2x bp overall). Discretize counts, run getfasta to get corresponding sequences, and then merge into final CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python3 python/rna_bed.py -gtf_filepath '../0-data/0-refs/agingeye/dmel-all-r6.55.gtf' -counts_filepath '../0-data/1-experimental/counts/agingeye/counts.xlsx' -sequence_length 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "/Users/nicolaskim/anaconda3/envs/dlenv/lib/python3.10/site-packages/pyranges/methods/init.py:45: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  return {k: v for k, v in df.groupby(grpby_key)}\n"
     ]
    }
   ],
   "source": [
    "!python3 python/rna_bed_default.py -gtf_filepath '../0-data/0-refs/agingeye/dmel-all-r6.55.gtf' -counts_filepath '../0-data/1-experimental/counts/agingeye/cts.txt' -sequence_length 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs getFasta on the files I just generated into bed format in the appropriate directory, using the appropriate reference genome (r6.55). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!./bash/rna_getfasta.sh '../0-data/0-refs/agingeye/dmel-all-chromosome-r6.55.fasta'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code converts the outputted fasta files from the getfasta script above into CSV format for processing. Displays first three rows of output file. Some filepaths I used for the bed files are the following: '../0-data/1-experimental/bed/agingeye/cts_bed.bed', '../0-data/1-experimental/bed/agingeye/D60vsD10.bed'. Some filepaths I used for the getfasta output are the following: '../0-data/2-final/0-getfasta/agingeye/cts_bed.out.fa', '../0-data/2-final/0-getfasta/agingeye/D60vsD10.out.fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "First three rows:                                              sequence  count\n",
      "0  GTGATCCACAGAAAACCCGAAATAAACGTTAAACAAGAAAAATTAA...      1\n",
      "1  TTTTTAACTGATATCGCGGAATAAATTGTGACTCTCACATCCCGAA...      1\n",
      "2  CCTAGTCGTTACAAAGCTCCAATAAAATTCTATACGGATTGTTTTT...      1\n",
      "Number of ones in whole dataset 20088\n",
      "umber of zeros in whole dataset 10499\n",
      "Number of ones in train dataset 16128\n",
      "Number of zeros in train dataset 8341\n",
      "Number of ones in test dataset 3960\n",
      "Number of zeros in test dataset 2158\n"
     ]
    }
   ],
   "source": [
    "!python3 python/rna_getfasta.py -input_bed_file '../0-data/1-experimental/bed/agingeye/cts_bed.bed' -input_fasta_file '../0-data/2-final/0-getfasta/agingeye/cts_bed.out.fa' -output_csv_file '../0-data/2-final/1-finalcsv/agingeye/' -output_csv_file_identifier 'cts_bed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess ATAC-seq data\n",
    "Run scripts to preprocess ATAC-seq data into non-overlapping windows of 600 bp each. Run bedtools getfasta to get the actual corresponding sequence for each window, using the proper reference genome. Note that the testing directory used DNAase-seq data, not ATAC-seq data, and used the hg19 grch37 reference genome (DNA) instead of what was needed for this project specifically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "!python3 python/atac_bed.py -input_bed_directory '../0-data/1-experimental/bed/encode/raw/' -output_bed_directory '../0-data/1-experimental/bed/encode/binned/' -max_overlap 200 -sequence_length 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputted files will be not in fasta format, but instead in tab delimited format since I wanted an easier way of labeling the sequences with appropriate counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!./bash/atac_getfasta.sh '../0-data/0-refs/encode/hg19.fa'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now process the outputted fasta file into CSV file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python3 python/atac_getfasta.py -input_bed_file '../0-data/1-experimental/bed/encode/binned/E003.bed' -input_fasta_file '../0-data/2-final/0-getfasta/encode/E003.out.fa' -output_csv_file '../0-data/2-final/1-finalcsv/E003'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model \n",
    "\n",
    "Set the configs, and then run the configuration script to set the appropiate variables. Subsequently load in the appropriate CSV data and run the model proper. The below are some of the relative filepaths to be used for training data. \n",
    "\n",
    "#### (D60 vs. D10)\n",
    "- '../0-data/2-final/1-finalcsv/agingeye/D60vsD10_train.csv'\n",
    "- '../0-data/2-final/1-finalcsv/agingeye/D60vsD10_test.csv'\n",
    "\n",
    "#### (Toy paths)\n",
    "- '../0-data/2-final/1-finalcsv/toy/toy_600bp_seq_1000_sample.csv' (log normalized counts, discretized based on LFC values)\n",
    "- '../0-data/2-final/1-finalcsv/toy/toy_100bp_seq_1000_sample.csv' (raw counts, binarized based on median exp value)\n",
    "\n",
    "\n",
    "#### (Median)\n",
    "- '../0-data/2-final/1-finalcsv/agingeye/cts_bed_train.csv'\n",
    "- '../0-data/2-final/1-finalcsv/agingeye/cts_bed_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "!python3 ../2-model/config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "0. Using mps device!\n",
      "Epoch [1/50], Step [383/383]\n",
      "Train Loss:  0.6294562500699693\n",
      "Training Accuracy:  0.6545598657884424\n",
      "Test Loss 0.6196519825607538\n",
      "Test Accuracy 0.6475380342453718\n",
      "\n",
      "\n",
      "Epoch [2/50], Step [383/383]\n",
      "Train Loss:  0.6022609275408264\n",
      "Training Accuracy:  0.6159257274072413\n",
      "Test Loss 0.5972984818120798\n",
      "Test Accuracy 0.5816628976414601\n",
      "\n",
      "\n",
      "Epoch [3/50], Step [383/383]\n",
      "Train Loss:  0.5652406967339877\n",
      "Training Accuracy:  0.5836946724600331\n",
      "Test Loss 0.5750479806835452\n",
      "Test Accuracy 0.5286458333333334\n",
      "\n",
      "\n",
      "Epoch [4/50], Step [383/383]\n",
      "Train Loss:  0.5228742813939525\n",
      "Training Accuracy:  0.5675840016755983\n",
      "Test Loss 0.5493855066597462\n",
      "Test Accuracy 0.5531798247247934\n",
      "\n",
      "\n",
      "Epoch [5/50], Step [383/383]\n",
      "Train Loss:  0.4818688329922001\n",
      "Training Accuracy:  0.5737461923930415\n",
      "Test Loss 0.5381534127518535\n",
      "Test Accuracy 0.5238829497247934\n",
      "\n",
      "\n",
      "Epoch [6/50], Step [383/383]\n",
      "Train Loss:  0.443194651883825\n",
      "Training Accuracy:  0.578521307392469\n",
      "Test Loss 0.5260155362387499\n",
      "Test Accuracy 0.5464381168906888\n",
      "\n",
      "\n",
      "Epoch [7/50], Step [383/383]\n",
      "Train Loss:  0.4117579415790717\n",
      "Training Accuracy:  0.5825989991815532\n",
      "Test Loss 0.5311098142216603\n",
      "Test Accuracy 0.5556126646697521\n",
      "\n",
      "\n",
      "Epoch [8/50], Step [383/383]\n",
      "Train Loss:  0.38960985508662294\n",
      "Training Accuracy:  0.5865504165853594\n",
      "Test Loss 0.5135280989731351\n",
      "Test Accuracy 0.5187260142217079\n",
      "\n",
      "\n",
      "Epoch [9/50], Step [383/383]\n",
      "Train Loss:  0.35774188233884757\n",
      "Training Accuracy:  0.5899792522114189\n",
      "Test Loss 0.5164778738593062\n",
      "Test Accuracy 0.568702028443416\n",
      "\n",
      "\n",
      "Epoch [10/50], Step [383/383]\n",
      "Train Loss:  0.3359285076355498\n",
      "Training Accuracy:  0.5975226905420618\n",
      "Test Loss 0.5203192622090379\n",
      "Test Accuracy 0.5689675851414601\n",
      "\n",
      "\n",
      "Epoch [11/50], Step [383/383]\n",
      "Train Loss:  0.31908956508568\n",
      "Training Accuracy:  0.5987096699659881\n",
      "Test Loss 0.5056806470577916\n",
      "Test Accuracy 0.5360814146697521\n",
      "\n",
      "\n",
      "Epoch [12/50], Step [383/383]\n",
      "Train Loss:  0.29728174474158425\n",
      "Training Accuracy:  0.60295248980933\n",
      "Test Loss 0.491461709762613\n",
      "Test Accuracy 0.5527943391352892\n",
      "\n",
      "\n",
      "Epoch [13/50], Step [383/383]\n",
      "Train Loss:  0.2806036871889553\n",
      "Training Accuracy:  0.6067873462061969\n",
      "Test Loss 0.5092117435609301\n",
      "Test Accuracy 0.5181178043906888\n",
      "\n",
      "\n",
      "Epoch [14/50], Step [383/383]\n",
      "Train Loss:  0.26329194369188486\n",
      "Training Accuracy:  0.6114031611783698\n",
      "Test Loss 0.5002805652717749\n",
      "Test Accuracy 0.5478943943356475\n",
      "\n",
      "\n",
      "Epoch [15/50], Step [383/383]\n",
      "Train Loss:  0.24127147019921022\n",
      "Training Accuracy:  0.6154381139471388\n",
      "Test Loss 0.5200766290848454\n",
      "Test Accuracy 0.519188596556584\n",
      "\n",
      "\n",
      "Epoch [16/50], Step [383/383]\n",
      "Train Loss:  0.22969770402338735\n",
      "Training Accuracy:  0.6159198993024253\n",
      "Test Loss 0.5293407229085764\n",
      "Test Accuracy 0.5026041666666666\n",
      "\n",
      "\n",
      "Epoch [17/50], Step [383/383]\n",
      "Train Loss:  0.21603273150970667\n",
      "Training Accuracy:  0.6189912812828083\n",
      "Test Loss 0.5177738140337169\n",
      "Test Accuracy 0.5506784537186226\n",
      "\n",
      "\n",
      "Epoch [18/50], Step [383/383]\n",
      "Train Loss:  0.20232389526874528\n",
      "Training Accuracy:  0.6217615473675043\n",
      "Test Loss 0.5248989656878015\n",
      "Test Accuracy 0.5398163376376033\n",
      "\n",
      "\n",
      "Epoch [19/50], Step [383/383]\n",
      "Train Loss:  0.18797755659638124\n",
      "Training Accuracy:  0.6244560487899083\n",
      "Test Loss 0.5334863405053815\n",
      "Test Accuracy 0.5444849918906888\n",
      "\n",
      "\n",
      "Epoch [20/50], Step [383/383]\n",
      "Train Loss:  0.18178887590376888\n",
      "Training Accuracy:  0.6264511843263013\n",
      "Test Loss 0.52127529711773\n",
      "Test Accuracy 0.5485540023073554\n",
      "\n",
      "\n",
      "Epoch [21/50], Step [383/383]\n",
      "Train Loss:  0.1691479421276648\n",
      "Training Accuracy:  0.6287008113089181\n",
      "Test Loss 0.5444589698066314\n",
      "Test Accuracy 0.540904262724022\n",
      "\n",
      "\n",
      "Epoch [22/50], Step [383/383]\n",
      "Train Loss:  0.1563281994653433\n",
      "Training Accuracy:  0.6310650566228064\n",
      "Test Loss 0.575835605772833\n",
      "Test Accuracy 0.5619089224686226\n",
      "\n",
      "\n",
      "Epoch [23/50], Step [383/383]\n",
      "Train Loss:  0.15457325723440465\n",
      "Training Accuracy:  0.6314322237246341\n",
      "Test Loss 0.5308353009944161\n",
      "Test Accuracy 0.5220326203852892\n",
      "\n",
      "\n",
      "Epoch [24/50], Step [383/383]\n",
      "Train Loss:  0.14206292834765138\n",
      "Training Accuracy:  0.6335516909706375\n",
      "Test Loss 0.5397947824870547\n",
      "Test Accuracy 0.5153594433019558\n",
      "\n",
      "\n",
      "Epoch [25/50], Step [383/383]\n",
      "Train Loss:  0.13861974053493367\n",
      "Training Accuracy:  0.6338702909473339\n",
      "Test Loss 0.5475146536094447\n",
      "Test Accuracy 0.551123903443416\n",
      "\n",
      "\n",
      "Epoch [26/50], Step [383/383]\n",
      "Train Loss:  0.13376182720415275\n",
      "Training Accuracy:  0.6349387666886531\n",
      "Test Loss 0.5302249579690397\n",
      "Test Accuracy 0.5224181059747934\n",
      "\n",
      "\n",
      "Epoch [27/50], Step [383/383]\n",
      "Train Loss:  0.1220922623092294\n",
      "Training Accuracy:  0.636941672927717\n",
      "Test Loss 0.5593706386474272\n",
      "Test Accuracy 0.5515522205581268\n",
      "\n",
      "\n",
      "Epoch [28/50], Step [383/383]\n",
      "Train Loss:  0.11963034809783452\n",
      "Training Accuracy:  0.6372175338840983\n",
      "Test Loss 0.5673806915680567\n",
      "Test Accuracy 0.5511667349686226\n",
      "\n",
      "\n",
      "Epoch [29/50], Step [383/383]\n",
      "Train Loss:  0.11540290029529802\n",
      "Training Accuracy:  0.6385327303689703\n",
      "Test Loss 0.557967420356969\n",
      "Test Accuracy 0.5308302491903305\n",
      "\n",
      "\n",
      "Epoch [30/50], Step [383/383]\n",
      "Train Loss:  0.10857976297422388\n",
      "Training Accuracy:  0.6397935317017079\n",
      "Test Loss 0.6064960113726556\n",
      "Test Accuracy 0.5453244925787052\n",
      "\n",
      "\n",
      "Epoch [31/50], Step [383/383]\n",
      "Train Loss:  0.1042973238867817\n",
      "Training Accuracy:  0.6407804146759193\n",
      "Test Loss 0.5922168473092219\n",
      "Test Accuracy 0.5398591694732507\n",
      "\n",
      "\n",
      "Epoch [32/50], Step [383/383]\n",
      "Train Loss:  0.1036302468425767\n",
      "Training Accuracy:  0.6410232500681367\n",
      "Test Loss 0.6425018354008595\n",
      "Test Accuracy 0.5142201203852892\n",
      "\n",
      "\n",
      "Epoch [33/50], Step [383/383]\n",
      "Train Loss:  0.0948829149423707\n",
      "Training Accuracy:  0.6415400037410677\n",
      "Test Loss 0.6265561959395806\n",
      "Test Accuracy 0.5481770833333334\n",
      "\n",
      "\n",
      "Epoch [34/50], Step [383/383]\n",
      "Train Loss:  0.09587469155226613\n",
      "Training Accuracy:  0.6420820123533044\n",
      "Test Loss 0.6588679368918141\n",
      "Test Accuracy 0.56005859375\n",
      "\n",
      "\n",
      "Epoch [35/50], Step [383/383]\n",
      "Train Loss:  0.09314557548865247\n",
      "Training Accuracy:  0.6425735111647424\n",
      "Test Loss 0.6168667559201518\n",
      "Test Accuracy 0.55029296875\n",
      "\n",
      "\n",
      "Epoch [36/50], Step [383/383]\n",
      "Train Loss:  0.09145754164293914\n",
      "Training Accuracy:  0.6431854563344552\n",
      "Test Loss 0.6173264763007561\n",
      "Test Accuracy 0.5486310993631681\n",
      "\n",
      "\n",
      "Epoch [37/50], Step [383/383]\n",
      "Train Loss:  0.09018811294881933\n",
      "Training Accuracy:  0.6427366965433325\n",
      "Test Loss 0.5816881656646729\n",
      "Test Accuracy 0.5347022339701653\n",
      "\n",
      "\n",
      "Epoch [38/50], Step [383/383]\n",
      "Train Loss:  0.085895370480461\n",
      "Training Accuracy:  0.6426920148473496\n",
      "Test Loss 0.5847995273458461\n",
      "Test Accuracy 0.5415553043906888\n",
      "\n",
      "\n",
      "Epoch [39/50], Step [383/383]\n",
      "Train Loss:  0.07816070944980254\n",
      "Training Accuracy:  0.644974667471943\n",
      "Test Loss 0.6099433104197184\n",
      "Test Accuracy 0.5361842106406888\n",
      "\n",
      "\n",
      "Epoch [40/50], Step [383/383]\n",
      "Train Loss:  0.0845547765967565\n",
      "Training Accuracy:  0.6442850149642705\n",
      "Test Loss 0.5837877822729448\n",
      "Test Accuracy 0.5623972037186226\n",
      "\n",
      "\n",
      "Epoch [41/50], Step [383/383]\n",
      "Train Loss:  0.07873384677379468\n",
      "Training Accuracy:  0.6453826309184182\n",
      "Test Loss 0.5858219169701139\n",
      "Test Accuracy 0.5581825654953718\n",
      "\n",
      "\n",
      "Epoch [42/50], Step [383/383]\n",
      "Train Loss:  0.0782544074735699\n",
      "Training Accuracy:  0.6456740333579539\n",
      "Test Loss 0.6063107904046774\n",
      "Test Accuracy 0.5538908305267493\n",
      "\n",
      "\n",
      "Epoch [43/50], Step [383/383]\n",
      "Train Loss:  0.07854125099183686\n",
      "Training Accuracy:  0.6457964223918965\n",
      "Test Loss 0.5920699248090386\n",
      "Test Accuracy 0.5443393637736639\n",
      "\n",
      "\n",
      "Epoch [44/50], Step [383/383]\n",
      "Train Loss:  0.07722145830361324\n",
      "Training Accuracy:  0.645710944351266\n",
      "Test Loss 0.6383854107310375\n",
      "Test Accuracy 0.5596302766352892\n",
      "\n",
      "\n",
      "Epoch [45/50], Step [383/383]\n",
      "Train Loss:  0.06953594931121672\n",
      "Training Accuracy:  0.6475079261914246\n",
      "Test Loss 0.6026142599682013\n",
      "Test Accuracy 0.5478087309747934\n",
      "\n",
      "\n",
      "Epoch [46/50], Step [383/383]\n",
      "Train Loss:  0.06847750539733365\n",
      "Training Accuracy:  0.6483199677330396\n",
      "Test Loss 0.6120690973475575\n",
      "Test Accuracy 0.5461896931131681\n",
      "\n",
      "\n",
      "Epoch [47/50], Step [383/383]\n",
      "Train Loss:  0.06845413140257135\n",
      "Training Accuracy:  0.6470183700556543\n",
      "Test Loss 0.6144622244561712\n",
      "Test Accuracy 0.5417351971069971\n",
      "\n",
      "\n",
      "Epoch [48/50], Step [383/383]\n",
      "Train Loss:  0.06646632756940613\n",
      "Training Accuracy:  0.64696397490352\n",
      "Test Loss 0.6094475000475844\n",
      "Test Accuracy 0.5437911183883747\n",
      "\n",
      "\n",
      "Epoch [49/50], Step [383/383]\n",
      "Train Loss:  0.06373844186437387\n",
      "Training Accuracy:  0.6484928664899682\n",
      "Test Loss 0.6114814784377813\n",
      "Test Accuracy 0.5466951069732507\n",
      "\n",
      "\n",
      "Epoch [50/50], Step [383/383]\n",
      "Train Loss:  0.06672389688810416\n",
      "Training Accuracy:  0.646441393203586\n",
      "Test Loss 0.6559800746229788\n",
      "Test Accuracy 0.5504642954717079\n",
      "\n",
      "\n",
      "{'training_loss_per_epoch': [0.6294562500699693, 0.6022609275408264, 0.5652406967339877, 0.5228742813939525, 0.4818688329922001, 0.443194651883825, 0.4117579415790717, 0.38960985508662294, 0.35774188233884757, 0.3359285076355498, 0.31908956508568, 0.29728174474158425, 0.2806036871889553, 0.26329194369188486, 0.24127147019921022, 0.22969770402338735, 0.21603273150970667, 0.20232389526874528, 0.18797755659638124, 0.18178887590376888, 0.1691479421276648, 0.1563281994653433, 0.15457325723440465, 0.14206292834765138, 0.13861974053493367, 0.13376182720415275, 0.1220922623092294, 0.11963034809783452, 0.11540290029529802, 0.10857976297422388, 0.1042973238867817, 0.1036302468425767, 0.0948829149423707, 0.09587469155226613, 0.09314557548865247, 0.09145754164293914, 0.09018811294881933, 0.085895370480461, 0.07816070944980254, 0.0845547765967565, 0.07873384677379468, 0.0782544074735699, 0.07854125099183686, 0.07722145830361324, 0.06953594931121672, 0.06847750539733365, 0.06845413140257135, 0.06646632756940613, 0.06373844186437387, 0.06672389688810416], 'training_accuracy_per_epoch': [0.6545598657884424, 0.6159257274072413, 0.5836946724600331, 0.5675840016755983, 0.5737461923930415, 0.578521307392469, 0.5825989991815532, 0.5865504165853594, 0.5899792522114189, 0.5975226905420618, 0.5987096699659881, 0.60295248980933, 0.6067873462061969, 0.6114031611783698, 0.6154381139471388, 0.6159198993024253, 0.6189912812828083, 0.6217615473675043, 0.6244560487899083, 0.6264511843263013, 0.6287008113089181, 0.6310650566228064, 0.6314322237246341, 0.6335516909706375, 0.6338702909473339, 0.6349387666886531, 0.636941672927717, 0.6372175338840983, 0.6385327303689703, 0.6397935317017079, 0.6407804146759193, 0.6410232500681367, 0.6415400037410677, 0.6420820123533044, 0.6425735111647424, 0.6431854563344552, 0.6427366965433325, 0.6426920148473496, 0.644974667471943, 0.6442850149642705, 0.6453826309184182, 0.6456740333579539, 0.6457964223918965, 0.645710944351266, 0.6475079261914246, 0.6483199677330396, 0.6470183700556543, 0.64696397490352, 0.6484928664899682, 0.646441393203586]}\n",
      "{'testing_loss_per_epoch': [0.6196519825607538, 0.5972984818120798, 0.5750479806835452, 0.5493855066597462, 0.5381534127518535, 0.5260155362387499, 0.5311098142216603, 0.5135280989731351, 0.5164778738593062, 0.5203192622090379, 0.5056806470577916, 0.491461709762613, 0.5092117435609301, 0.5002805652717749, 0.5200766290848454, 0.5293407229085764, 0.5177738140337169, 0.5248989656878015, 0.5334863405053815, 0.52127529711773, 0.5444589698066314, 0.575835605772833, 0.5308353009944161, 0.5397947824870547, 0.5475146536094447, 0.5302249579690397, 0.5593706386474272, 0.5673806915680567, 0.557967420356969, 0.6064960113726556, 0.5922168473092219, 0.6425018354008595, 0.6265561959395806, 0.6588679368918141, 0.6168667559201518, 0.6173264763007561, 0.5816881656646729, 0.5847995273458461, 0.6099433104197184, 0.5837877822729448, 0.5858219169701139, 0.6063107904046774, 0.5920699248090386, 0.6383854107310375, 0.6026142599682013, 0.6120690973475575, 0.6144622244561712, 0.6094475000475844, 0.6114814784377813, 0.6559800746229788], 'testing_accuracy_per_epoch': [0.6475380342453718, 0.5816628976414601, 0.5286458333333334, 0.5531798247247934, 0.5238829497247934, 0.5464381168906888, 0.5556126646697521, 0.5187260142217079, 0.568702028443416, 0.5689675851414601, 0.5360814146697521, 0.5527943391352892, 0.5181178043906888, 0.5478943943356475, 0.519188596556584, 0.5026041666666666, 0.5506784537186226, 0.5398163376376033, 0.5444849918906888, 0.5485540023073554, 0.540904262724022, 0.5619089224686226, 0.5220326203852892, 0.5153594433019558, 0.551123903443416, 0.5224181059747934, 0.5515522205581268, 0.5511667349686226, 0.5308302491903305, 0.5453244925787052, 0.5398591694732507, 0.5142201203852892, 0.5481770833333334, 0.56005859375, 0.55029296875, 0.5486310993631681, 0.5347022339701653, 0.5415553043906888, 0.5361842106406888, 0.5623972037186226, 0.5581825654953718, 0.5538908305267493, 0.5443393637736639, 0.5596302766352892, 0.5478087309747934, 0.5461896931131681, 0.5417351971069971, 0.5437911183883747, 0.5466951069732507, 0.5504642954717079]}\n",
      "/Users/nicolaskim/Desktop/research/singh_lab/basset_basenji/revised_agingeye_classification/1-preprocessing/../2-model/train_test.py:226: UserWarning: constrained_layout not applied because axes sizes collapsed to zero.  Try making figure larger or axes decorations smaller.\n",
      "  plt.savefig(f'../3-viz/debug/3-11-debug/loss_curves_{id}')\n",
      "/Users/nicolaskim/Desktop/research/singh_lab/basset_basenji/revised_agingeye_classification/1-preprocessing/../2-model/train_test.py:240: UserWarning: constrained_layout not applied because axes sizes collapsed to zero.  Try making figure larger or axes decorations smaller.\n",
      "  plt.savefig(f'../3-viz/debug/3-11-debug/accuracy_curves_{id}')\n"
     ]
    }
   ],
   "source": [
    "!python3 ../2-model/train_test.py -primarymodel 'DeepChrome' -trainfile '../0-data/2-final/1-finalcsv/agingeye/cts_bed_train.csv' -testfile '../0-data/2-final/1-finalcsv/agingeye/cts_bed_test.csv' -seqlen 100 -optim 'Adam' -loss 'BCE' -batchsize 64"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
